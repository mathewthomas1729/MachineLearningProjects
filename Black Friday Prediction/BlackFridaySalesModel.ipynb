{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to process features data set to create categorical dummy variables   \n",
    "def process_categories(df):\n",
    "    categorical_variables = ['Gender','Age','City_Category','Stay_In_Current_City_Years']\n",
    "    dummy_variables=pd.get_dummies(df[categorical_variables])\n",
    "    df_towork=pd.concat([dummy_variables,df],axis=1).drop(categorical_variables,axis=1)\n",
    "    df_towork=pd.concat([pd.get_dummies(df['Occupation'],prefix='Occupation'),df_towork],axis=1).drop('Occupation',axis=1)\n",
    "    \n",
    "    #Since male and female are the only 2 genders in the data we can drop one of the variables\n",
    "    df_towork.drop('Gender_M',axis=1,inplace=True)\n",
    "    \n",
    "    cat1=pd.get_dummies(df_towork['Product_Category_1'],prefix='Product_category_1')\n",
    "    cat2=pd.get_dummies(df_towork['Product_Category_2'],prefix='Product_category_2')\n",
    "    cat3=pd.get_dummies(df_towork['Product_Category_3'],prefix='Product_category_3')\n",
    "    df_towork=pd.concat([df_towork,cat1,cat2,cat3],axis=1).drop(['Product_Category_1','Product_Category_2','Product_Category_3'],axis=1)\n",
    "    return df_towork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_missing_columns(df):\n",
    "    missing_columns=[]\n",
    "    for i in range(1,21):\n",
    "        colname='Product_category_1_' + str(i)\n",
    "        if colname not in  df.columns:\n",
    "            missing_columns.append(colname)\n",
    "    for i in range(1,21):\n",
    "        colname='Product_category_2_' + str(float(i))\n",
    "        if colname not in  df.columns:\n",
    "            missing_columns.append(colname)\n",
    "    for i in range(1,21):\n",
    "        colname='Product_category_3_' + str(float(i))\n",
    "        if colname not in  df.columns:\n",
    "            missing_columns.append(colname)\n",
    "            \n",
    "    for i in missing_columns:\n",
    "        df[i]=0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_prod_categories(df):\n",
    "    for i in range(1,21):\n",
    "        new_column_name = 'Prod_category_' + str(i)\n",
    "        category1_name = 'Product_category_1_' + str(i)\n",
    "        category2_name = 'Product_category_2_' + str(float(i))\n",
    "        category3_name = 'Product_category_3_' + str(float(i))\n",
    "        df[new_column_name] = (df[category1_name] | df[category2_name] | df[category3_name])\n",
    "        cols_to_drop=[category1_name,category2_name,category3_name]\n",
    "        df=df.drop(cols_to_drop,axis=1)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=process_categories(train)\n",
    "df_train=identify_missing_columns(df_train)\n",
    "df_train_final=collate_prod_categories(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 61 columns):\n",
      " #   Column                         Non-Null Count   Dtype \n",
      "---  ------                         --------------   ----- \n",
      " 0   Occupation_0                   550068 non-null  uint8 \n",
      " 1   Occupation_1                   550068 non-null  uint8 \n",
      " 2   Occupation_2                   550068 non-null  uint8 \n",
      " 3   Occupation_3                   550068 non-null  uint8 \n",
      " 4   Occupation_4                   550068 non-null  uint8 \n",
      " 5   Occupation_5                   550068 non-null  uint8 \n",
      " 6   Occupation_6                   550068 non-null  uint8 \n",
      " 7   Occupation_7                   550068 non-null  uint8 \n",
      " 8   Occupation_8                   550068 non-null  uint8 \n",
      " 9   Occupation_9                   550068 non-null  uint8 \n",
      " 10  Occupation_10                  550068 non-null  uint8 \n",
      " 11  Occupation_11                  550068 non-null  uint8 \n",
      " 12  Occupation_12                  550068 non-null  uint8 \n",
      " 13  Occupation_13                  550068 non-null  uint8 \n",
      " 14  Occupation_14                  550068 non-null  uint8 \n",
      " 15  Occupation_15                  550068 non-null  uint8 \n",
      " 16  Occupation_16                  550068 non-null  uint8 \n",
      " 17  Occupation_17                  550068 non-null  uint8 \n",
      " 18  Occupation_18                  550068 non-null  uint8 \n",
      " 19  Occupation_19                  550068 non-null  uint8 \n",
      " 20  Occupation_20                  550068 non-null  uint8 \n",
      " 21  Gender_F                       550068 non-null  uint8 \n",
      " 22  Age_0-17                       550068 non-null  uint8 \n",
      " 23  Age_18-25                      550068 non-null  uint8 \n",
      " 24  Age_26-35                      550068 non-null  uint8 \n",
      " 25  Age_36-45                      550068 non-null  uint8 \n",
      " 26  Age_46-50                      550068 non-null  uint8 \n",
      " 27  Age_51-55                      550068 non-null  uint8 \n",
      " 28  Age_55+                        550068 non-null  uint8 \n",
      " 29  City_Category_A                550068 non-null  uint8 \n",
      " 30  City_Category_B                550068 non-null  uint8 \n",
      " 31  City_Category_C                550068 non-null  uint8 \n",
      " 32  Stay_In_Current_City_Years_0   550068 non-null  uint8 \n",
      " 33  Stay_In_Current_City_Years_1   550068 non-null  uint8 \n",
      " 34  Stay_In_Current_City_Years_2   550068 non-null  uint8 \n",
      " 35  Stay_In_Current_City_Years_3   550068 non-null  uint8 \n",
      " 36  Stay_In_Current_City_Years_4+  550068 non-null  uint8 \n",
      " 37  User_ID                        550068 non-null  int64 \n",
      " 38  Product_ID                     550068 non-null  object\n",
      " 39  Marital_Status                 550068 non-null  int64 \n",
      " 40  Purchase                       550068 non-null  int64 \n",
      " 41  Prod_category_1                550068 non-null  int64 \n",
      " 42  Prod_category_2                550068 non-null  int64 \n",
      " 43  Prod_category_3                550068 non-null  uint8 \n",
      " 44  Prod_category_4                550068 non-null  uint8 \n",
      " 45  Prod_category_5                550068 non-null  uint8 \n",
      " 46  Prod_category_6                550068 non-null  uint8 \n",
      " 47  Prod_category_7                550068 non-null  int64 \n",
      " 48  Prod_category_8                550068 non-null  uint8 \n",
      " 49  Prod_category_9                550068 non-null  uint8 \n",
      " 50  Prod_category_10               550068 non-null  uint8 \n",
      " 51  Prod_category_11               550068 non-null  uint8 \n",
      " 52  Prod_category_12               550068 non-null  uint8 \n",
      " 53  Prod_category_13               550068 non-null  uint8 \n",
      " 54  Prod_category_14               550068 non-null  uint8 \n",
      " 55  Prod_category_15               550068 non-null  uint8 \n",
      " 56  Prod_category_16               550068 non-null  uint8 \n",
      " 57  Prod_category_17               550068 non-null  uint8 \n",
      " 58  Prod_category_18               550068 non-null  uint8 \n",
      " 59  Prod_category_19               550068 non-null  int64 \n",
      " 60  Prod_category_20               550068 non-null  int64 \n",
      "dtypes: int64(8), object(1), uint8(52)\n",
      "memory usage: 65.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining steps above to encapsulate it in a single function\n",
    "def train_and_test(df,k=0):\n",
    "    #features\n",
    "    features=df.select_dtypes(include=('int64','uint8')).drop(['Purchase'],axis=1).columns\n",
    "    \n",
    "    if k==0:\n",
    "        train=df[:440055]\n",
    "        test=df[440055:]\n",
    "        lr = linear_model.LinearRegression()\n",
    "        lr.fit(train[features],train['Purchase'])\n",
    "        predict=lr.predict(test[features])\n",
    "        mse=mean_squared_error(predict,test['Purchase'])\n",
    "        rmse=np.sqrt(mse)\n",
    "        return rmse\n",
    "    \n",
    "    if k==1:\n",
    "        df_shuffle = df.sample(frac=1,)\n",
    "        fold_one=df_shuffle[:440055]\n",
    "        fold_two=df_shuffle[440055:]\n",
    "        lr = linear_model.LinearRegression()\n",
    "        \n",
    "        lr.fit(fold_one[features],fold_one['Purchase'])\n",
    "        predict_one=lr.predict(fold_two[features])\n",
    "        mse_one=mean_squared_error(predict_one,fold_two['Purchase'])\n",
    "        rmse_one=np.sqrt(mse_one)\n",
    "        \n",
    "        lr = linear_model.LinearRegression()\n",
    "        lr.fit(fold_two[features],fold_two['Purchase'])\n",
    "        predict_two=lr.predict(fold_one[features])\n",
    "        mse_two=mean_squared_error(predict_two,fold_one['Purchase'])\n",
    "        rmse_two=np.sqrt(mse_two)\n",
    "        \n",
    "        avg_rmse=np.mean([rmse_one,rmse_two])\n",
    "        \n",
    "        return avg_rmse\n",
    "        \n",
    "    else:\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_vals=[]\n",
    "        for train_index,test_index, in kf.split(df):\n",
    "            train=df.iloc[train_index]\n",
    "            test=df.iloc[test_index]\n",
    "            lr = linear_model.LinearRegression()\n",
    "            lr.fit(train[features],train['Purchase'])       \n",
    "            predict=lr.predict(test[features])\n",
    "            mse=mean_squared_error(predict,test['Purchase'])\n",
    "            rmse=np.sqrt(mse)\n",
    "            rmse_vals.append(rmse)\n",
    "        avg_rmse=np.mean(rmse_vals)\n",
    "        return avg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3621.602521704796"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_test(df_train_final,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=process_categories(test)\n",
    "df_test=identify_missing_columns(df_test)\n",
    "df_test_final=collate_prod_categories(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df_train_final.select_dtypes(include=('int64','uint8')).drop(['Purchase'],axis=1).columns\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(df_train_final[features],df_train_final['Purchase'])       \n",
    "predict=lr.predict(df_test_final[features])\n",
    "submissions=pd.DataFrame({'Purchase':predict,'User_ID':df_test_final['User_ID'],'Product_ID':df_test_final['Product_ID']})\n",
    "submissions.to_csv('submission_0328_b.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining steps above to encapsulate it in a single function\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "def train_and_test(df,k=0):\n",
    "    #features\n",
    "    features=df.select_dtypes(include=('int64','uint8')).drop(['Purchase'],axis=1).columns\n",
    "    \n",
    "    if k==0:\n",
    "        train=df[:440055]\n",
    "        test=df[440055:]\n",
    "        lr = linear_model.LinearRegression()\n",
    "        lr.fit(train[features],train['Purchase'])\n",
    "        predict=lr.predict(test[features])\n",
    "        mse=mean_squared_error(predict,test['Purchase'])\n",
    "        rmse=np.sqrt(mse)\n",
    "        return rmse\n",
    "    \n",
    "    if k==1:\n",
    "        df_shuffle = df.sample(frac=1,)\n",
    "        fold_one=df_shuffle[:440055]\n",
    "        fold_two=df_shuffle[440055:]\n",
    "        model = KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
    "                      metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
    "                      weights='uniform')\n",
    "        \n",
    "        model.fit(fold_one[features],fold_one['Purchase'])\n",
    "        predict_one=model.predict(fold_two[features])\n",
    "        mse_one=mean_squared_error(predict_one,fold_two['Purchase'])\n",
    "        rmse_one=np.sqrt(mse_one)\n",
    "        \n",
    "        model = KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
    "                      metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
    "                      weights='uniform')\n",
    "        model.fit(fold_two[features],fold_two['Purchase'])\n",
    "        predict_two=model.predict(fold_one[features])\n",
    "        mse_two=mean_squared_error(predict_two,fold_one['Purchase'])\n",
    "        rmse_two=np.sqrt(mse_two)\n",
    "        \n",
    "        avg_rmse=np.mean([rmse_one,rmse_two])\n",
    "        \n",
    "        return avg_rmse\n",
    "        \n",
    "    else:\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_vals=[]\n",
    "        for train_index,test_index, in kf.split(df):\n",
    "            train=df.iloc[train_index]\n",
    "            test=df.iloc[test_index]\n",
    "            model = KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
    "                      metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
    "                      weights='uniform')\n",
    "            model.fit(train[features],train['Purchase'])       \n",
    "            predict=model.predict(test[features])\n",
    "            mse=mean_squared_error(predict,test['Purchase'])\n",
    "            rmse=np.sqrt(mse)\n",
    "            rmse_vals.append(rmse)\n",
    "        avg_rmse=np.mean(rmse_vals)\n",
    "        return avg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4428.832198169276"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_test(df_train_final,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_rf(df,k=0):\n",
    "    #features\n",
    "    features=df.select_dtypes(include=('int64','uint8')).drop(['Purchase'],axis=1).columns\n",
    "    \n",
    "    if k==0:\n",
    "        train=df[:440055]\n",
    "        test=df[440055:]\n",
    "        model = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                        max_samples=None, min_impurity_decrease=0.0,\n",
    "                        min_impurity_split=None, min_samples_leaf=1,\n",
    "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                        n_estimators=100, n_jobs=None, oob_score=False,\n",
    "                        random_state=None, verbose=0, warm_start=False)\n",
    "        model.fit(train[features],train['Purchase'])\n",
    "        predict=model.predict(test[features])\n",
    "        mse=mean_squared_error(predict,test['Purchase'])\n",
    "        rmse=np.sqrt(mse)\n",
    "        return rmse\n",
    "    \n",
    "    if k==1:\n",
    "        df_shuffle = df.sample(frac=1,)\n",
    "        fold_one=df_shuffle[:440055]\n",
    "        fold_two=df_shuffle[440055:]\n",
    "        model = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                        max_samples=None, min_impurity_decrease=0.0,\n",
    "                        min_impurity_split=None, min_samples_leaf=1,\n",
    "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                        n_estimators=100, n_jobs=None, oob_score=False,\n",
    "                        random_state=None, verbose=0, warm_start=False)\n",
    "        \n",
    "        model.fit(fold_one[features],fold_one['Purchase'])\n",
    "        predict_one=model.predict(fold_two[features])\n",
    "        mse_one=mean_squared_error(predict_one,fold_two['Purchase'])\n",
    "        rmse_one=np.sqrt(mse_one)\n",
    "        \n",
    "        model = KNeighborsRegressor(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
    "                      metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
    "                      weights='uniform')\n",
    "        model.fit(fold_two[features],fold_two['Purchase'])\n",
    "        predict_two=model.predict(fold_one[features])\n",
    "        mse_two=mean_squared_error(predict_two,fold_one['Purchase'])\n",
    "        rmse_two=np.sqrt(mse_two)\n",
    "        \n",
    "        avg_rmse=np.mean([rmse_one,rmse_two])\n",
    "        \n",
    "        return avg_rmse\n",
    "        \n",
    "    else:\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_vals=[]\n",
    "        for train_index,test_index, in kf.split(df):\n",
    "            train=df.iloc[train_index]\n",
    "            test=df.iloc[test_index]\n",
    "            model = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                        max_samples=None, min_impurity_decrease=0.0,\n",
    "                        min_impurity_split=None, min_samples_leaf=1,\n",
    "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                        n_estimators=100, n_jobs=None, oob_score=False,\n",
    "                        random_state=None, verbose=0, warm_start=False)\n",
    "            model.fit(train[features],train['Purchase'])       \n",
    "            predict=model.predict(test[features])\n",
    "            mse=mean_squared_error(predict,test['Purchase'])\n",
    "            rmse=np.sqrt(mse)\n",
    "            rmse_vals.append(rmse)\n",
    "        avg_rmse=np.mean(rmse_vals)\n",
    "        return avg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_and_test_rf(df_train_final,10)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df_train_final.select_dtypes(include=('int64','uint8')).drop(['Purchase'],axis=1).columns\n",
    "all_X=df_train_final[features]\n",
    "all_y=df_train_final['Purchase']\n",
    "train_X,test_X,train_y,test_y = train_test_split(all_X,all_y,test_size=.2,random_state=0)\n",
    "model = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                        max_samples=None, min_impurity_decrease=0.0,\n",
    "                        min_impurity_split=None, min_samples_leaf=1,\n",
    "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                        n_estimators=100, n_jobs=None, oob_score=False,\n",
    "                        random_state=None, verbose=0, warm_start=False)\n",
    "model.fit(train_X[features],train_y)\n",
    "predictions=model.predict(test_X[features])\n",
    "single_accuracy=model.score(test_X[features],test_y)\n",
    "scores=cross_val_score(model,all_X,all_y,cv=10)\n",
    "cross_validated_accuracy = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(single_accuracy)\n",
    "print(cross_validated_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
